from datetime import datetime

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from deepforest import CascadeForestRegressor
import logging
from logging.handlers import RotatingFileHandler
import shutil
import os
from skopt import BayesSearchCV
# 配置日志
logger = logging.getLogger()
logger.setLevel(logging.INFO)

if not logger.handlers:
    handler1 = RotatingFileHandler("pd.log", maxBytes=10 ** 6, backupCount=5, encoding='utf-8')
    handler2 = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    handler1.setFormatter(formatter)
    handler2.setFormatter(formatter)
    logger.addHandler(handler1)
    logger.addHandler(handler2)

# 贝叶斯优化调参
def optimize_cascade_forest(X_train, y_train):

    param_space = {
        'n_bins': (10, 255), 
        'bin_subsample': (200000, 500000), 
        'max_layers': (10, 60),  
        'n_estimators': (2, 10),
        'n_trees': (10, 1000), 
    }


    cascade_forest = CascadeForestRegressor(n_jobs=-1, partial_mode='true', random_state=42)

    bayes_search = BayesSearchCV(cascade_forest, param_space, n_iter=50, cv=5, n_jobs=-1,
                                 scoring='neg_mean_squared_error', random_state=42)

    bayes_search.fit(X_train, y_train)

    best_params = bayes_search.best_params_
    logging.info(f"调优后的最佳参数: {best_params}")

    return best_params


def main():
    # 数据加载
    file_path = r'D:\datasets\merge\yearly_merged\merged_2015_2022_combined.csv'

    try:
        df = pd.read_csv(file_path)  # .sample(frac=0.001, random_state=42)
        logging.info(f"成功加载数据，形状: {df.shape}")

        # 必要的数据预处理
        df = df.dropna(subset=['time'])
        df['date'] = pd.to_datetime(df['time'].astype(str), format='%Y%m%d', errors='coerce')
        df = df.dropna(subset=['date'])
        df = df[df['date'].dt.year.between(2015, 2022)]
        logging.info(f"预处理后数据形状: {df.shape}")
    except Exception as e:
        logging.error(f"数据加载失败: {e}")
        return

    scaler = StandardScaler()


    X_train = df[['time', 'lat', 'lon', 'dm', 'gp', 'pp', 'sh', 'sp', 'te',
                  'NO2', 'CO', 'nt', 'nv','sin_day','eh','AEF','DY']]
    y_train = df['XCO2']

    X_train = X_train.values
    X_train = scaler.fit_transform(X_train)
    best_params=optimize_cascade_forest(X_train,y_train)
    model = CascadeForestRegressor(n_estimators=best_params['n_estimators'],
            n_trees=best_params['n_trees'],
            max_layers=best_params['max_layers'],
            n_bins=best_params['n_bins'],
            bin_subsample=best_params['bin_subsample'],
            random_state=42,
            n_jobs=-1,
            partial_mode='true')
    model.fit(X_train, y_train)

    predict_dir = r'E:\DataSet\merge\pd'
    output_dir = r'E:\DataSet\merge\pdresults'

    start_filename = '20150101_merged.csv'
    for filename in os.listdir(predict_dir):
        if filename.endswith('.csv'):
            try:
                if filename >= start_filename:
                    predict_file_path = os.path.join(predict_dir, filename)
                    df_predict = pd.read_csv(predict_file_path)
                    logging.info(f"加载预测数据: {filename}, 形状: {df_predict.shape}")

                    df_predict['date'] = pd.to_datetime(df_predict['time'].astype(str), format='%Y%m%d',
                                                        errors='coerce')
                    df_predict = df_predict.dropna(subset=['date'])


                    X_predict = df_predict[[
                        'time', 'lat', 'CT', 'lon', 'dm', 'gp', 'pp', 'sh', 'sp', 'te',
                        'NO2', 'CO', 'nt','nv','sin_day','eh','AEF','DY']]
                    X_predict = X_predict.values
                    X_predict = scaler.transform(X_predict)

                    y_predict = model.predict(X_predict)
                    df_predict['predicted_XCO2'] = y_predict
                    df_predict['predicted_XCO2'] = df_predict['predicted_XCO2'].astype('float32')

                    df_predict = df_predict[['time', 'lat', 'lon', 'predicted_XCO2']]

                    temp_output_dir = r'D:\temp_predictions' 
                    if not os.path.exists(temp_output_dir):
                        os.makedirs(temp_output_dir)

                    temp_output_csv_path = os.path.join(temp_output_dir, filename)
                    df_predict.to_csv(temp_output_csv_path, index=False)
                    logging.info(f"预测结果已临时保存为 CSV: {temp_output_csv_path}")

                    final_output_csv_path = os.path.join(output_dir, filename)
                    shutil.move(temp_output_csv_path, final_output_csv_path)
                    logging.info(f"预测结果已移动到最终目标目录: {final_output_csv_path}")

            except Exception as e:
                logging.error(f"处理文件 {filename} 时出错: {e}")


if __name__ == "__main__":
    main()
